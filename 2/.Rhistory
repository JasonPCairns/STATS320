for (i in 1:size.M){
distscores[i] <- 1/sum(M[i,])
}
for (i in 1:size.M){
for (j in 1:size.M){
if (M[i,j] == 1){
M[i,j] <- distscores[i]
}
}
}
return (M)
}
GetS <- function(M){
size.M <- nrow(M)
alpha <- 0.85
Z <- rep(1/size.M, size.M)
v <- Z
vP <- alpha*v%*%M + (1-alpha)*Z
curr = c(rep(0,size.M))
for (i in 1:size.M){
while (vP[i] - curr[i] > 0.0000005){
curr <- vP
vP <- alpha*vP%*%M + (1-alpha)*Z
}
}
return(vP)
}
GetS(GetM(mat))
View(mat)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,10^2),nrow=10)
for (i in 0:9){
for (j in 0:9){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i == j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(0,5,0.2)
}
if (i < j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i >= 5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:9){
for (j in 0:9){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i == j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(0,5,0.2)
}
if (i < j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i >= 5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:9){
for (j in 0:9){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i == j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(0,5,0.2)
}
if (i < j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i >= 5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:9){
for (j in 0:9){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i <= j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i > 5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
dbinom(1,5,0.2)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:9){
for (j in 0:9){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j=>5) & (i<=5) & (j<=(5+i))){
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>=5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# 0 probability for anything other than the 5 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
knitr::opts_chunk$set(fig.height=3)
require(R330)
# 0 probability for anything other than the 4 options below
P <- matrix(rep(0,11^2),nrow=11)
for (i in 0:10){
for (j in 0:10){
if (i<=5 & j<i){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2)
}
if (i<=j & j<=5){
P[i+1,j+1] <- (1/3)*dbinom(j,5,0.2) + (2/3)*dbinom(j-i,5,0.2)
}
if (i>5  & j<=5){
P[i+1,j+1] <- dbinom(j,5,0.2)
}
if ((j>5) & (i<=5) & (j<=(5+i))){
P[i+1,j+1] <- (2/3)*dbinom(j-i,5,0.2)
}
}
}
P
rowSums(P)
# This gives fixation time for A allele
FixationTime <- function (A = 50, N = 100){
time <- 0
# Loop forms new generations until fixation
while (A != 0 & A != N){
time <- time + 1
A <- rbinom(1,N,(A/N))
}
# Returns time to fixation
return (time)
}
# This gives fixation variance from large number of simulations
FixVar <- function(M=10000){
times <- rep(NA,M)
# Fills in the vector with each entry being a simulated fixation time
for (i in 1:M){
times[i] <- FixationTime()
}
# returns variance of the vector
return (var(times))
}
#adjacency matrix of Question 4 graph
mat <- matrix(c(0,0,1,1,0,0,1,0,0,
1,0,1,0,0,0,0,0,0,
1,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,1,0,0,
0,0,0,1,0,1,0,0,0,
0,0,0,0,0,0,1,0,0,
0,0,1,0,0,0,0,1,1,
0,0,0,0,0,0,1,0,0,
0,0,0,0,0,0,1,0,0),nrow=9,byrow=TRUE)
GetM <- function (M){
size.M <- nrow(M)
distscores <- rep(NA,size.M)
for (i in 1:size.M){
distscores[i] <- 1/sum(M[i,])
}
for (i in 1:size.M){
for (j in 1:size.M){
if (M[i,j] == 1){
M[i,j] <- distscores[i]
}
}
}
return (M)
}
GetS <- function(M){
size.M <- nrow(M)
alpha <- 0.85
Z <- rep(1/size.M, size.M)
v <- Z
vP <- alpha*v%*%M + (1-alpha)*Z
curr = c(rep(0,size.M))
for (i in 1:size.M){
while (vP[i] - curr[i] > 0.0000005){
curr <- vP
vP <- alpha*vP%*%M + (1-alpha)*Z
}
}
return(vP)
}
GetS(GetM(mat))
---
title: "STATS XXX Assignment X"
author: "Jason Cairns 8092261"
date: 'Due Date: XX-XX-XX XX:XX'
output: pdf_document
number_sections: yes
fig_caption: yes
---
```{r global_options, include=FALSE}
#knitr::opts_chunk$set(out.width = '40%')
require(R330)
set.seed(1234)
```
\textbf{The data}
\newline
\textit{After a crime is committed, investigators build a profile of the perpetrator based on whatever evidence is available. Sometimes handwriting samples are found at crime scenes. In this
assignment our aim is to build a classifier to predict whether a handwriting sample was
written by a male or a female. The data set \textbf{handwriting-train.csv} contains the following variables
measured from total of 232 handwriting samples:
\begin{itemize}
\item \textbf{gender}: whether the sample was written by a female ("F") or a male ("M").
\item \textbf{chaincode1-chaincode4}: Four variables measuring features extracted from the chain-
codes of the handwriting contours.
\item \textbf{curvature1-curvature4}: Four variables measuring the curvature of the handwriting.
\item \textbf{direction1}: A variable measuring the direction of the handwriting.
\item \textbf{tortuosity1}: A variable measuring the tortuosity (or twistedness) of the handwriting.
\end{itemize}
}
# Question 1
## a
```{r}
train.df <- read.csv("handwriting-train.csv")
pairs(train.df)
```
From the pairs plot, there are not many clear correlations between variables. chaincode3 and direction1 appear to have some positive linear correlation, and there may be correlations between the three chaincodes, but beyond these, it is difficult to tease out more correlations by eye.
## b
```{r, out.width='80%'}
hw.glm <- glm(gender ~ chaincode1 + chaincode2 + chaincode3 + chaincode4 + curvature1
+ curvature2 + curvature3 + curvature4 + direction1 + tortuosity1,
family = binomial, data = train.df)
summary(hw.glm)
```
Our model has a fairly high residual deviance, at 288.83, meaning a significant amount of variance was left unaccounted for by our model. Some explanatory variables were demonstrated to have a high level of significance, with chaincode1 being the most significant, whereas most explanatory variables were clearly insignificant.
# Question 2
To find the final model, the full model was first fitted:
```{r, warning=FALSE}
hw.full.glm <- glm(gender ~ chaincode1*chaincode2*chaincode3*chaincode4*curvature1
*curvature2*curvature3*curvature4*direction1*tortuosity1,
family = binomial, data = train.df)
```
Then, using a stepwise procedure, a simpler model was used for variable selection:
```{r}
null.glm<- glm(gender ~ 1, family = binomial, data = train.df)
step.glm <- step(null.glm, formula(hw.full.glm), direction = "both", trace = FALSE)
```
The final model was assessed via anova:
```{r}
anova(step.glm, test = "Chisq")
summary(step.glm)
```
With the understanding that AIC tends to select for more complex models, for the sake of simplicity and potential generalisation, several other models were tried, with none having near the AIC or predictive capacities. A final model was chosen based on the stepwise result, with the interaction term chaincode1:curvature1 removed for simplicity, as it was not significant in the ANOVA, and made little difference to the AIC.
final model:
```{r}
final.hw.glm <- glm(formula = gender ~ chaincode1 + curvature2 + curvature1 +
curvature3 + tortuosity1 + curvature2:curvature1 + curvature1:curvature3 +
chaincode1:tortuosity1 + curvature1:tortuosity1,
family = binomial, data = train.df)
```
# Question 3
## a
```{r}
HMD <- hatvalues(final.hw.glm)
plot(HMD, ylab = "HMD's", type = "h", cex = 1.5, cex.axis = 1.5, cex.lab = 1.5,
main = "Index plot of HMD's")
text(HMD)
abline(h= 3*5/232)
```
The Hat Marix Diagonals Index demonstrates a high HMD for this model. There are a high number of "outlying" covariates
```{r}
dev.r <- residuals(final.hw.glm, type = "deviance")
pea.r <- residuals(final.hw.glm, type = "pearson")
dev.change <- dev.r^2 + pea.r^2 * HMD / (1-HMD); bigdev <- 4
plot(dev.change, ylab = "Deviance change", type = "h", cex = 1.5, cex.axis = 1.5,
cex.lab = 1.5, main = "Index plot of deviance changes")
text(dev.change); abline(h = bigdev, lty = 2, col = "gray50")
```
There are a few points that clearly impact deviance, however they could be genuine points - there is no real evidence that they are wrong. If they are to be deleted, the regression coefficients would be increased, making the fitted probabilities more extreme and the predictive ability of the model to be overstated.
```{r, out.width = '50%'}
plot(final.hw.glm)
```
All the observations will have distinct covariate patterns, as the residuals lie along two curves, and therefore have little or no diagnostic value. That is, even if everything is ok, the pattern demonstrated above remains.
```{r}
HLstat(final.hw.glm)
```
Finally, the Hosmer-Lemeshow statistic has a p-value of 0.155. A p-value of less than 0.05 indicates problems, and as that is not the case, it appears our model fits correctly.
## b
```{r}
pred <- predict(final.hw.glm, type = "response")
predicted <- ifelse(pred < 0.5, "F", "M")
table(with(train.df, gender), predicted)
```
In our final model, a female is given as "failure", with male as "success". With this in mind, we can state the specificity as:
$\frac{84}{84 + 30} = 73.7\%$
With specificity as:
$\frac{91}{91 + 27} = 77.1\%$
And In-sample-error-rate:
$\frac{30 + 27}{232} = 24.5\%$
```{r}
ROC.curve(final.hw.glm)
```
The ROC curve looks good, with AUC = 0.8021
```{r}
cross.val(final.hw.glm)
1-err.boot(final.hw.glm)$Err
```
Finally, our bootstrap mean correctly classified is given as 0.7540
Our model seems to fit well, and doesn't require any particular adjustments, as type I error is no more or less favourable than type II error in this case.
# Question 4
```{r}
test.df <- read.csv("handwriting-test-blind.csv")
gender.pred <- rep(NA, dim(test.df)[1])
for (i in 1:dim(test.df)[1]){
gender.pred[i] <- ifelse(predict(final.hw.glm, train.df[i,], type = "response") < 0.5,
"F", "M")
}
pred.df <- data.frame(gender.pred, test.df)
write.csv(pred.df,file="8092261.csv",row.names=FALSE)
```
#knitr::opts_chunk$set(out.width = '40%')
require(R330)
set.seed(1234)
train.df <- read.csv("handwriting-train.csv")
pairs(train.df)
hw.glm <- glm(gender ~ chaincode1 + chaincode2 + chaincode3 + chaincode4 + curvature1
+ curvature2 + curvature3 + curvature4 + direction1 + tortuosity1,
family = binomial, data = train.df)
summary(hw.glm)
hw.full.glm <- glm(gender ~ chaincode1*chaincode2*chaincode3*chaincode4*curvature1
*curvature2*curvature3*curvature4*direction1*tortuosity1,
family = binomial, data = train.df)
null.glm<- glm(gender ~ 1, family = binomial, data = train.df)
step.glm <- step(null.glm, formula(hw.full.glm), direction = "both", trace = FALSE)
anova(step.glm, test = "Chisq")
summary(step.glm)
final.hw.glm <- glm(formula = gender ~ chaincode1 + curvature2 + curvature1 +
curvature3 + tortuosity1 + curvature2:curvature1 + curvature1:curvature3 +
chaincode1:tortuosity1 + curvature1:tortuosity1,
family = binomial, data = train.df)
HMD <- hatvalues(final.hw.glm)
plot(HMD, ylab = "HMD's", type = "h", cex = 1.5, cex.axis = 1.5, cex.lab = 1.5,
main = "Index plot of HMD's")
text(HMD)
abline(h= 3*5/232)
dev.r <- residuals(final.hw.glm, type = "deviance")
pea.r <- residuals(final.hw.glm, type = "pearson")
dev.change <- dev.r^2 + pea.r^2 * HMD / (1-HMD); bigdev <- 4
plot(dev.change, ylab = "Deviance change", type = "h", cex = 1.5, cex.axis = 1.5,
cex.lab = 1.5, main = "Index plot of deviance changes")
text(dev.change); abline(h = bigdev, lty = 2, col = "gray50")
plot(final.hw.glm)
HLstat(final.hw.glm)
pred <- predict(final.hw.glm, type = "response")
predicted <- ifelse(pred < 0.5, "F", "M")
table(with(train.df, gender), predicted)
ROC.curve(final.hw.glm)
cross.val(final.hw.glm)
1-err.boot(final.hw.glm)$Err
test.df <- read.csv("handwriting-test-blind.csv")
gender.pred <- rep(NA, dim(test.df)[1])
for (i in 1:dim(test.df)[1]){
gender.pred[i] <- ifelse(predict(final.hw.glm, train.df[i,], type = "response") < 0.5,
"F", "M")
}
pred.df <- data.frame(gender.pred, test.df)
write.csv(pred.df,file="8092261.csv",row.names=FALSE)
